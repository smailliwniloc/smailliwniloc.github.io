\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{csquotes}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[margin=0.5in]{geometry}
\usepackage{amsthm}
\usepackage{enumitem}
\usepackage{tikz}
\usetikzlibrary{calc}
\newtheorem{question}{Question}
\newtheorem*{question*}{Question}
\newtheorem{theorem}{Theorem}
\newtheorem*{theorem*}{Theorem}
\newtheorem{lemma}{Lemma}

\theoremstyle{definition}
\newtheorem{answer}{Answer}
\newtheorem*{answer*}{Answer}

\theoremstyle{definition}
\newtheorem{verify}{Verification}
\newtheorem*{verify*}{Verification}

\numberwithin{equation}{section}


\title{Analysis HW 10}
\author{Colin Williams}

\begin{document}
\maketitle

\section*{Question 1}
Let $X \subset \mathbb{R}^n$ be an open connected set. Let $f: X \to \mathbb{R}^n$ be differentiable and such that for all $x \in X$, $f'(x) = 0$. Prove that $f$ is a constant function. 

\begin{proof}$ $
\\Let $y \in f(X)$. I will use ``Lemma 4" to show that $Y := f^{-1}(\{y\})$ is open in $X$. Lemma 4 stated that if $U \subset \mathbb{R}^n$ were open and convex with $f: U \to \mathbb{R}^n$ differentiable, then if there exists some $M > 0$ such that $||f'(x)|| \leq M$ for all $x \in U$, then for all $a, b \in U$, $|f(b) - f(a)| \leq M|b - a|$. Let $x \in Y$. Since $Y \subset X$ and $X$ is open, then we know there is some open ball (of radius $r > 0$) centered at $x$ which is contained inside of $X$. Call this $U_r(x) =: U$ from Lemma 4. Note that $U$ is clearly open and any ball is convex, so $U$ is convex as well. Since $f$ is differentiable on $X$, it is indeed differentiable on $U$ as well. Furthermore $||f'(x)|| = 0$ by assumption so that $M > 0$ exists such that $||f'(x)|| \leq M$ for all $x \in U$ for any choice of $M$. Therefore, let $b \in U$ and by the conclusion of Lemma 4, we have that 
\begin{align*}
|f(b) - f(x)| \leq M|b - x| &< Mr\\
\implies -Mr < f(b) - f(x) &< Mr\\
\implies -Mr + y < f(b) &< Mr + y
\end{align*}
Thus, letting $M \to 0$ (since the above argument worked for all $M > 0$), we get that $f(b) = y$. In other words $b \in Y$ and since $b$ was an arbitrary point of $U$, we get that $U \subset Y$. Furthermore, since $x$ was arbitrary, we get that every point of $Y$ has an open neighborhood in $Y$, so $Y$ is indeed an open subset of $X$. 
\\
\\Note also that $f^{-1}(\{y\})$ is closed since $\{y\}$ is closed and $f$ is continuous; thus, $f^{-1}(\{y\})$ is a clopen subset of $X$. However, since $X$ is connected, the only open and closed subsets of $X$ are the empty set and $X$ itself [To show this, note that if there were another clopen set $U$, then $\{U, U^c\}$ would be a separation of $X$]. This means that $f^{-1}(\{y\})$ is either $\emptyset$ or $X$. However, since $y \in f(X)$, we know that $f^{-1}(\{y\}) \neq \emptyset$ which forces $f^{-1}(\{y\}) = X$. In other words, $f(x) = y$ for all $x \in X$ so $f$ is indeed a constant function. 
\end{proof}


\section*{Question 2}
Let $u, v \in \mathbb{R}^n$ such that $|u| = |v| = 1$. Use the Contraction Principle to show that there exists a unique $x \in \mathbb{R}^n$ such that $x = u + \dfrac{|x|}{2}v$. Show by example that there does not necessarily exist an $x \in \mathbb{R}^n$ such that $x = u + |x|v$. 

\begin{proof}$ $
\\Consider the function $\varphi: X \to X$ given by 
\begin{align*}
\varphi(x) = u + \frac{|x|}{2}v
\end{align*}
I will first show that $\varphi$ is a strict contraction. Consider
\begin{align*}
|\varphi(x) - \varphi(y)| &= \left|u + \frac{|x|}{2}v - \left(u + \frac{|y|}{2}v\right)\right|\\
&= \left|\left(\frac{|x|}{2} - \frac{|y|}{2}\right)v\right|\\
&= \frac{1}{2}\big| |x| - |y| \big| &\text{since $v$ is a unit vector}\\
&\leq \frac{1}{2} |x - y| &\text{by Reverse Triangle Inequality}
\end{align*}
Therefore, $\varphi$ is a strict contraction with contraction constant of $1/2 < 1$. Thus, by the Contraction Principle, there exists some unique $x \in \mathbb{R}^n$ such that $\varphi(x) = x$. In other words, $\exists ! \; x \in \mathbb{R}^n$ such that
\begin{align*}
u + \frac{|x|}{2}v = x
\end{align*}
However, a counterexample exists when we do not have a strict contraction. Consider $u = e_1, v = e_2 \in \mathbb{R}^2$ and assume that there exists some $x \in \mathbb{R}^2$ such that
\begin{align*}
x = e_1 + |x|e_2 = (1, |x|)
\end{align*}
By taking the Euclidean norm of both sides, we get
\begin{align*}
|x| &= \sqrt{1 + |x|^2}\\
\implies |x|^2 &= 1 + |x|^2\\
\implies 0 &= 1
\end{align*}
This last statement is clearly absurd so our assumption of the existence of such an $x$ must have been false. Therefore, we see that if we have merely a (non-strict) contraction, then the Contraction Principle does not necessarily hold.
\end{proof}


\section*{Question 3}
Consider $f: \mathbb{R}^4 \to \mathbb{R}^3$ given by 
\begin{align*}
f(x, y, z, t) = (3x + y - z + t^2, x - y + 2z + t, 2x + 2y - 3z + 2t).
\end{align*}
\begin{enumerate}[label = (\alph*)]
\item Show that $f$ is continuously differentiable. 
	\begin{itemize}
	\item To do this, I will simply verify that each partial derivative is continuous:
	\begin{align*}
	D_1f(x, y, z, t) &= (3, 1, 2)\\
	D_2f(x, y, z, t) &= (1, -1, 2)\\
	D_3f(x, y, z, t) &= (-1, 2, -3)\\
	D_4f(x, y, z, t) &= (2t, 1, 2)
	\end{align*}
	\item The first three partial derivatives are simply constant functions and trivially continuous. The fourth partial derivative has two constant components and one linear component, so it is also continuous. Therefore, all of the partial derivatives exist and are continuous, so $f$ is continuously differentiable. 
	\end{itemize}
\item Evaluate $[f'(x, y, z, t)](\alpha, \beta, \gamma, \delta)$.
	\begin{itemize}
	\item From the calculations above, it is clear to see that
	\begin{align*}
	[f'(x, y, z, t)](\alpha, \beta, \gamma, \delta) &= \sum_{j = 1}^4 v^j D_j f(x, y, z, t)\\
	&= \alpha (3, 1, 2) + \beta(1, -1, 2) + \gamma(-1, 2, -3) + \delta (2t, 1, 2)\\
	&= \bigg(3\alpha + \beta - \gamma + 2t\delta, \alpha - \beta + 2\gamma + \delta, 2\alpha + 2\beta - 3\gamma + 2\delta\bigg)
	\end{align*}
	\end{itemize}
\item Evaluate the ``blocks" $[f'_{x, y, z}(x, y, z, t)](\alpha, \beta, \gamma)$ and $[f'_{x, y, t}(x, y, z, t)](\alpha, \beta, \delta)$. 
	\begin{itemize}
	\item The first block corresponds to $\delta = 0$ and the second block corresponds to $\gamma = 0$ in the above calculation. Therefore,
	\begin{align*}
	[f'_{x, y, z}(x, y, z, t)](\alpha, \beta, \gamma) &= \bigg(3\alpha + \beta - \gamma, \alpha - \beta + 2\gamma, 2\alpha + 2\beta - 3\gamma\bigg)\\
	[f'_{x, y, t}(x, y, z, t)](\alpha, \beta, \delta) &= \bigg(3\alpha + \beta + 2t\delta, \alpha - \beta + \delta, 2\alpha + 2\beta + 2\delta\bigg)
	\end{align*}
	\end{itemize}
\item Show that for $(x, y, z, t)$ in a sufficiently small neighborhood of $(0, 0, 0, 0)$ the linear transformation $f'_{x, y, t}(x, y, z, t)$ is invertible.
	\begin{itemize}
	\item To do this, I will show that the kernel of $f'_{x, y, t}(x, y, z, t)$ is equal to $\{0\}$. Let $(\alpha, \beta, \delta) \in \mathbb{R}^3$ be such that $[f'_{x, y, t}(x, y, z, t)](\alpha, \beta, \delta) = (0,0,0)$. In other words,
	\begin{align*}
	\bigg(3\alpha + \beta + 2t\delta, \alpha - \beta + \delta, 2\alpha + 2\beta + 2\delta\bigg) = (0,0,0)
	\end{align*}	
	\item This gives a system of three equations:
	\begin{align*}
	\begin{cases}
	3\alpha + \beta + 2t\delta &= 0\\
	\alpha - \beta + \delta &= 0\\
	2\alpha + 2\beta + 2\delta &= 0
	\end{cases}
	\end{align*}
	\item From the last equation, we get that $\alpha = -\beta - \delta$. Plugging this into the second equation, we get:
	\begin{align*}
	(-\beta - \delta) - \beta + \delta &= 0\\
	\implies -2\beta &= 0\\
	\implies \beta &= 0
	\end{align*}	
	\item This also simplifies our expression with $\alpha$ to simply be $\alpha = -\delta$. Plugging this into the first equation (with $\beta = 0$), we get
	\begin{align*}
	-3\delta + 2t\delta &= 0\\
	\implies (2t - 3)\delta &= 0\\
	\implies \delta = \alpha &= 0
	\end{align*}		
	\item where the last equality follows as long as $t \neq \frac{3}{2}$. In particular, as long as $t < 1$, then this will hold and in fact $(\alpha, \beta, \delta) = (0,0,0)$ so that any vector in the kernel of $f'_{x, y, t}(x, y, z, t)$ must be the zero vector. Thus, our neighborhood of $(0,0,0,0)$ where $f'_{x, y, t}(x, y, z, t)$ is invertible can be chosen as $U_1(0) \subset \mathbb{R}^4$ where the $x, y, z$-coordinates do not necessarily matter, but more importantly $t$ is restricted to be less than 1. 
	\item I could have chosen our neighborhood to have radius of $\frac{3}{2}$, but choosing 1 worked fine for our purposes. 
	\end{itemize}
\item Show that the linear transformation $f'_{x, y, z}(x, y, z, t)$ is not invertible for any $(x, y, z, t)$. 
	\begin{itemize}
	\item Recall that 
	\begin{align*}
	[f'_{x, y, z}(x, y, z, t)](\alpha, \beta, \gamma) &= \bigg(3\alpha + \beta - \gamma, \alpha - \beta + 2\gamma, 2\alpha + 2\beta - 3\gamma\bigg).
	\end{align*}
	\item Notice this shows that the linear transformation $f'_{x, y, z}(x, y, z, t)$ does not in fact depend on $(x, y, z, t)$ at all. Therefore, if I simply show that linear transformation is not invertible, then it is necessarily not invertible for any $(x, y, z, t)$. 
	\item To show the non-invertibility, I will find a non-zero vector in the kernel of $f'_{x, y, z}(x, y, z, t)$. Notice, if\\$[f'_{x, y, z}(x, y, z, t)](\alpha, \beta, \gamma) = 0$, then we have the following system of equations
	\begin{align*}
	\begin{cases}
	3\alpha + \beta - \gamma &= 0\\
	\alpha - \beta + 2\gamma &= 0\\
	2\alpha + 2\beta - 3\gamma &= 0
	\end{cases}
	\end{align*}
	\item Notice by adding the first and second equation or by adding the third equation and twice the second equation, we get
	\begin{align*}
	4\alpha + \gamma = 0
	\end{align*}
	\item This has a possible solution of $(\alpha, \gamma) = (1, -4)$. With this choice of $\alpha$ and $\gamma$, we can plug into the second equation to get that $\beta = -7$. Furthermore, we see indeed that
	\begin{align*}
	[f'_{x, y, z}(x, y, z, t)](1, -7, -4) &= \bigg(3(1) - 7 + 4, 1 + 7 + 2(-4), 2(1) + 2(-7) - 3(-4) \bigg)\\
	&= (0,0,0)
	\end{align*}
	\item Thus, $f'_{x, y, z}(x, y, z, t)$ has a non-zero kernel and cannot possibly be invertible, regardless of the choice of $(x, y, z, t)$.
	\end{itemize}
\item Show by straighforward computation that in a neighborhood of $(0, 0, 0, 0)$ the equation $f(x, y, z, t) = 0$ can be solved for $x, y, t$ in terms of $z$ and cannot be solved for $x, y, z$ in terms of $t$. 
	\begin{itemize}
	\item If we have that $f(x, y, z, t) = 0$, then we have the following system of equations:
	\begin{align*}
	\begin{cases}
	3x + y - z + t^2 &= 0\\
	x - y + 2z + t &= 0\\
	2x + 2y - 3z + 2t &= 0
	\end{cases}
	\end{align*}
	\item Na\"ively solving for $x$ in the second equation and $y$ in the third equation yields:
	\begin{align*}
	x &= y - 2z - t\\
	y &= -x + \frac{3}{2}z - t
	\end{align*}
	\item Plugging $y$ into the expression for $x$ gives us:
	\begin{align*}
	x &= -x + \frac{3}{2}z - t - 2z - t\\
	\implies 2x &= -\frac{z}{2} - 2t\\
	\implies x &= -\frac{z}{4} - t
	\end{align*}
	\item Using the expression for $y$ once more:
	\begin{align*}
	y &= -\left(\frac{-z}{4} - t\right) + \frac{3}{2}z - t\\
	&= \frac{7}{4}z
	\end{align*}
	\item Now, plugging $x$ and $y$ into our first equation we get
	\begin{align*}
	3\left(-\frac{z}{4} - t\right) + \frac{7}{4}z - z + t^2 &= 0\\
	\implies -3t + t^2 &= 0\\
	\implies t(t - 3) &= 0
	\end{align*}
	\item Since we are in a neighborhood of $(0,0,0,0)$, we must choose $t = 0$ in this case. We now have our solution for $f(x, y, z, t) = 0$ in terms of $z$:
	\begin{align*}
	(x, y, z, t) = \left(-\frac{z}{4}, \frac{7}{4}z, z, 0\right) = (-0.25, 1.75, 1, 0)z
	\end{align*}
	\item Recall that we were forced to choose $t = 0$ when doing the previous computations. That fact will be true regardless of which order we decide to manipulate the equations. Therefore, $t$ is always fixed as zero so we cannot possibly solve for $x, y, z$ in terms of $t$ (except for the trivial solution $(x, y, z, t) = (0,0,0,0)$ where $x = y = z = t$, but this is only at a point, not on a neighborhood). 
	\end{itemize}
\end{enumerate}



\end{document}