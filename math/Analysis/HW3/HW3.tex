\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{csquotes}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[margin=0.5in]{geometry}
\usepackage{amsthm}
\usepackage{enumitem}
\usepackage{tikz}
\usetikzlibrary{calc}
\newtheorem{question}{Question}
\newtheorem*{question*}{Question}
\newtheorem{theorem}{Theorem}
\newtheorem*{theorem*}{Theorem}
\newtheorem{lemma}{Lemma}

\theoremstyle{definition}
\newtheorem{answer}{Answer}
\newtheorem*{answer*}{Answer}

\theoremstyle{definition}
\newtheorem{verify}{Verification}
\newtheorem*{verify*}{Verification}


\title{Analysis Homework 3}
\author{Colin Williams}

\begin{document}
\maketitle

\section*{Question 1}
Let the sequence $(x_n)$ be defined recursively as $x_1 = \sqrt{2}$, $x_{n+1} = \sqrt{2 + \sqrt{x_n}}$. Prove that the sequence is convergent. 

\begin{proof}$ $
\\First, I will show that the sequence is bounded. In particular, $x_n \in (0, 2)$ for all $n \in \mathbb{N}$. I will prove this by induction:
\\
\\\underline{Base Case:} This is clear to see since $x_1 = \sqrt{2} \in (0, 2)$. 
\\\underline{Inductive Step:} Assume that $x_n \in (0, 2)$ for some $n \in \mathbb{N}$. Then we have the following inequalities:
\begin{align*}
x_{n+1} &= \sqrt{2 + \sqrt{x_n}}\\
&< \sqrt{2 + \sqrt{2}} &\text{by inductive hypothesis}\\
&= 1.847\ldots < 2\\
x_{n+1} &= \sqrt{2 + \sqrt{x_n}}\\
&> \sqrt{2 + \sqrt{0}} &\text{by inductive hypothesis}\\
&= \sqrt{2} > 0
\end{align*}
Thus, $x_{n+1} \in (0, 2)$ and the claim is proven inductively. 
\\
\\Next, I will show that the sequence $(x_n)$ is monotone increasing. To do this, I will prove that $x_n \leq x_{n+1}$ holds by induction:
\\
\\\underline{Base Case:} It is clear numerically that $x_1 < x_2$ since $x_1 = \sqrt{2} = 1.414\ldots < 1.785\ldots = \sqrt{2 + \sqrt{\sqrt{2}}} = x_2$.
\\\underline{Inductive Step:} Assume that for some $n \in \mathbb{N}$, the inequality $x_{n} < x_{n+1}$ holds true. From this inequality, we can see the following:
\begin{align*}
x_n &< x_{n+1} &\text{by inductive hypothesis}\\
\implies \sqrt{x_n} &< \sqrt{x_{n+1}}\\
\implies 2 + \sqrt{x_n} &< 2 + \sqrt{x_{n+1}}\\
\implies \sqrt{2 + \sqrt{x_n}} &< \sqrt{2 + \sqrt{x_{n+1}}}\\
\implies x_{n + 1} &< x_{n+2}
\end{align*}
Thus, the sequence is monotone increasing. Therefore, we have shown that $(x_n)$ is both bounded and monotonic and since our metric space here is simply $\mathbb{R}$, we have proven in class that $(x_n)$ must be convergent. Therefore, there exists some $a \in [0, 2] \subset \mathbb{R}$ such that $\lim_{n \to \infty} x_n = a$. Finding what this $a$ must be would involve finding the roots to a quartic polynomial which I won't attempt to do.
\end{proof}

\section*{Question 2}
Let $(x_n)$ and $(y_n)$ be two real sequences such that 
\begin{align*}
\left\{\limsup_{n \to \infty} x_n, \limsup_{n \to \infty} y_n \right\} \neq \{+\infty, -\infty\}.
\end{align*}
Prove that 
\begin{align*}
\limsup_{n \to \infty} (x_n + y_n) \leq \limsup_{n \to \infty} x_n + \limsup_{n \to \infty} y_n
\end{align*}

\begin{proof}$ $
\\Let us fix some $N \in \mathbb{N}$. Then the following inequalities follow simply from the definition of the supremum:
\begin{align*}
x_n &\leq \sup \{x_n : n \geq N\} \quad \forall \; n \geq N\\
y_n &\leq \sup \{y_n : n \geq N\} \quad \forall \; n \geq N
\end{align*}
These inequalities clearly imply
\begin{align*}
x_n + y_n &\leq \sup \{x_n : n \geq N\} + \sup \{y_n : n \geq N\} \quad \forall \; n \geq N
\end{align*}
Since this holds for all $n \geq N$, then the supremum over all $n \geq N$ of the left side must also be no greater than the right hand side:
\begin{align*}
\sup\{x_n + y_n : n \geq N\} &\leq \sup \{x_n : n \geq N\} + \sup \{y_n : n \geq N\}
\end{align*}
Thus, by taking limits as $N \to \infty$, we get:
\begin{align*}
\lim_{N \to \infty} \sup\{x_n + y_n : n \geq N\} &\leq \lim_{N \to \infty}\bigg( \sup \{x_n : n \geq N\} + \sup \{y_n : n \geq N\}\bigg)\\
\implies \limsup_{n \to \infty} (x_n + y_n) &\leq \limsup_{n \to \infty} x_n + \limsup_{n \to \infty} y_n
\end{align*}
which proves the desired statement. Note the condition that $\left\{\limsup_{n \to \infty} x_n, \limsup_{n \to \infty} y_n \right\} \neq \{+\infty, -\infty\}$ guaranteed that we never ran into a case of $\infty - \infty$ which means all calculations I did above were indeed valid as calculations of numbers in the extended real line $\overline{\mathbb{R}} = \mathbb{R} \cup \{-\infty, +\infty\}$. 
\end{proof}

\section*{Question 3}
Let $(x_n)$ be a sequence of non-negative real numbers such that 
\begin{align*}
\sum_{n = 1}^\infty x_n = +\infty.
\end{align*}
Prove that 
\begin{align*}
\sum_{n = 1}^\infty \frac{x_n}{1 + x_n} = +\infty
\end{align*}

\begin{proof}$ $
\\First, assume that $(x_n)$ is unbounded, i.e. that $\lim_{n \to \infty} x_n = +\infty$. If this is the case, then 
\begin{align*}
\lim_{n \to \infty} \left(\frac{x_n}{1 + x_n} \right) &= 1 &\text{since the numerator and denominator have the same rate of divergence.}
\end{align*}
Thus, since $(x_n/(1 + x_n))_n$ does not converge to zero, then it is impossible for the series to converge. On the other hand, if $(x_n)$ is bounded, but the series still diverges, then we have that $x_n \leq M$ for all $n$ and we can say that 
\begin{align*}
\sum_{n = 1}^\infty \frac{x_n}{1 + x_n} &\geq \sum_{n = 1}^\infty \frac{x_n}{1 + M}\\
&= \frac{1}{1 + M} \sum_{n = 1}^\infty x_n\\
&= +\infty
\end{align*}
Therefore, the series still diverges when $(x_n)$ is bounded, so it must always diverge. 
\end{proof}

\section*{Question 4}
Let $(x_n)$ be a sequence of non-negative real numbers such that
\begin{align*}
\sum_{n = 1}^\infty x_n < +\infty.
\end{align*}
Prove that $\liminf_{n \to \infty} nx_n = 0.$

\begin{proof}$ $
\\Assume that $\liminf_{n \to \infty} nx_n \neq 0$. Since $(x_n)$ is non-negative, then we must have that $\liminf_{n \to \infty} nx_n > 0$, say equal to some $\delta > 0$. Note that 
\begin{align*}
\liminf_{n \to \infty} nx_n &= \lim_{N \to \infty} \inf \{nx_n : n \geq N\}
\end{align*}
Thus, for this limit to be equal to $\delta$ we must have that for every $\varepsilon$, there exists some $M \in \mathbb{N}$, such that 
\begin{align*}
|\inf\{nx_n : n \geq N\} - \delta| < \varepsilon \quad \forall \; N \geq M
\end{align*}
Furthermore, since the sequence of infimums must be an increasing sequence as $N$ increases, then we know that $\delta$ must be greater than $\inf\{nx_n : n \geq N\}$ for all $N$. Thus, we can say that 
\begin{align*}
\delta - \inf\{nx_n : n \geq N\} &< \varepsilon & \forall \; N \geq M\\
\implies \inf\{nx_n : n \geq N\} &> \delta - \varepsilon & \forall \; N \geq M
\end{align*}
By taking $\varepsilon$ to be equal to $\delta / 2$, we see that $\inf\{nx_n : n \geq N\}$ is positive for all $N \geq M$. In particular, this means that $nx_n \geq \inf\{nx_n : n \geq M\} =: \mu > 0$ for all $n \geq M$. Thus, we see that $x_n \geq \mu/n$ for all $n \geq M$. However, using this fact we get:
\begin{align*}
\sum_{n = 1}^\infty x_n &= \sum_{n = 1}^{M-1} x_n + \sum_{n = M}^\infty x_n\\
&\geq \sum_{n = 1}^{M-1} x_n + \sum_{n = M}^\infty \frac{\mu}{n}
\end{align*}
However, note that the far right summation is divergent since it is the tail of a scaled version of the harmonic series. Thus, since the first summation is finite, we can see that $\sum x_n$ diverges. But this is a contradiction to our assumption that $\sum x_n < + \infty$. Therefore, our assumption was wrong and we do indeed have that $\liminf_{n \to \infty} nx_n = 0$. 
\end{proof}

\begin{question*}$ $
\\Does $\lim_{n \to \infty} nx_n$ always exist?
\end{question*}

\begin{answer*}$ $
\\No, consider the series
\begin{align*}
x_n = \begin{cases}
\frac{1}{n} &\text{for $n$ a power of 2}\\
\frac{1}{n^2} &\text{else.}
\end{cases}
\end{align*}
\end{answer*}

\begin{proof}$ $
\\In this series above, we have convergence since 
\begin{align*}
\sum_{n = 1}^\infty x_n &= \sum_{n \text{ a power of 2}} \frac{1}{n} + \sum_{n \text{ not a power of 2}} \frac{1}{n^2}\\
&= \sum_{k = 1}^\infty \frac{1}{2^k} + \sum_{n = 1}^\infty \frac{1}{n^2} - \sum_{k = 1}^\infty \frac{1}{2^{2k}}\\
&\leq \sum_{k = 1}^\infty \frac{1}{2^k} + \sum_{n = 1}^\infty \frac{1}{n^2}
\end{align*}
Notice that the two series in the last expression are both convergent, so $\sum x_n$ is convergent as it is bounded by the sum of two convergent series. Furthermore $x_n > 0$ for all $n$ so $(x_n)$ is non-negative meaning the hypotheses of the question are satisfied. However, if we consider the subsequence $(2^k \cdot x_{2^k})$ of $(nx_n)$, then 
\begin{align*}
\lim_{k \to \infty} (2^k \cdot x_{2^k}) = \lim_{k \to \infty} 2^k \cdot \frac{1}{2^k} = 1
\end{align*}
Thus, $\limsup(nx_n) \geq 1$. On the other hand by taking any other subsequence that does not contain powers of 2, say $(n_k \cdot x_{n_k})$ of $(nx_n)$, it is clear to see that
\begin{align*}
\lim_{k \to \infty} (n_k \cdot x_{n_k}) = \lim_{k \to \infty} n_k \cdot \frac{1}{n_k^2} = \lim_{k \to \infty} \frac{1}{n_k} = 0
\end{align*}
Thus, $\liminf(nx_n) \leq 0$. However, this means that $\liminf(nx_n) \neq \limsup(nx_n)$ which means that $\lim(nx_n)$ does not exist. 
\end{proof}

\section*{Question 5}
Let $(x_n)$ and $(y_n)$ be two real sequences such that $(x_n)$ is monotonic and bounded and that $\sum_{n = 1}^\infty y_n$ is convergent. Prove that 
\begin{align*}
\sum_{n = 1}^\infty x_n y_n 
\end{align*}
is convergent as well. 


\begin{proof}$ $
\\Recall the Dirichlet Test which we proved in class: If the following conditions are met
\begin{enumerate}[label = (\alph*)]
\item $\displaystyle \sup\left\{\left|\sum_{n = 1}^N y_n \right| : N \in \mathbb{N}\right\} < + \infty$
\item $\forall \; n \in \mathbb{N}, x_n \geq x_{n + 1}$
\item $\lim_{n \to \infty} x_n = 0$
\end{enumerate}
then $$\sum_{n =1}^\infty x_n y_n$$ is convergent. In our case, we have that $\sum y_n$ is convergent. This means that the sequence of partial sums of $y_n$ is convergent. In particular, the sequence of partial sums must have a finite supremum, so condition (a) is met. For condition (b), we are given that $(x_n)$ is monotonic; thus, we can assume that it is monotonic decreasing (otherwise, replace $(x_n)$ with $(-x_n)$ to conclude that $-\sum x_n y_n$ converges which happens if and only if $\sum x_n y_n$ converges). For condition (c) we know that $(x_n)$ is not only monotonic, but also bounded. We have proven that bounded monotonic sequences converge; however, they will likely not converge to 0. Thus, let $L$ be the limit of $(x_n)$ and define the sequence 
\begin{align*}
c_n = x_n - L.
\end{align*}
Then $(c_n)$ is also monotonic decreasing since $(x_n)$ is and in fact $\lim_{n \to \infty} c_n = L - L = 0$. Thus, we can apply the Dirichlet Test to conclude that 
\begin{align*}
\sum_{n = 1}^\infty c_n y_n = \sum_{n = 1}^\infty x_n y_n - \sum_{n = 1}^\infty L y_n
\end{align*}
converges. Furthermore, it is clear to see that the far-right sequence converges as it is simply a scalar multiple of a convergent sequence. Thus, we can rearrange terms to get
\begin{align*}
\sum_{n = 1}^\infty x_n y_n = \sum_{n = 1}^\infty c_n y_n  + \sum_{n = 1}^\infty L y_n
\end{align*}
and conclude that the sequence we are interested in must converge since it is the sum of two convergent sequences. 
\end{proof}


\end{document}